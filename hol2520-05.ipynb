{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d162c9-3c4e-4a41-bf4e-64e4a4d2488f",
   "metadata": {},
   "source": [
    "![Top <](./images/watsonxdata.png \"watsonxdata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f325cb87-acd2-4eae-8757-793b1e15fb6d",
   "metadata": {},
   "source": [
    "# Lab 5: Hybrid Multi-vector queries\n",
    "\n",
    "Milvus allows you to search for objects using multiple types of information, such as text, images, and audio. This is called hybrid or multi-vector search. It combines searches across different fields to enhance the search experience. This labs shows how this can be done.\n",
    "\n",
    "The first steps for creating and loading a database are similar to lab 1, 2, 3 and 4. Nevertheless you should execute them carefullly since we are creating an additional vector this time. In additional we are using slightly different functions for most operations by using the MilvusClient interface. The querying will start in the section **Hybrid Multi-Vector Queries with Milvus**. \n",
    "\n",
    "The first step is to make sure that the Milvus extensions are loaded into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb61b9c-2cee-4097-9825-561bff73af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymilvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182278fc-2640-438d-be0d-11748f309513",
   "metadata": {},
   "source": [
    "### We check the version since most of the rest of the notebook requires a current pymilvus version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86be9d5-66ff-4e14-95f0-22dd1038b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymilvus\n",
    "print(pymilvus.__version__)\n",
    "print (dir(pymilvus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c6e6d-b973-42d5-b883-1733700e6d02",
   "metadata": {},
   "source": [
    "## Local Connection\n",
    "\n",
    "A local connection assumes that you are running your Jupyter notebook inside the same server that is running watsonx.data and the Milvus server. The connection user is the default watsonx.data userid (ibmlhadmin). You need to generate the certificate that will be used by the connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f69e4a4-7d5d-47bc-999a-bd4a804cdc0f",
   "metadata": {},
   "source": [
    "### Generate the Connection Certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fcd41-b112-4728-850f-d2d0adbdb93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f /tmp/presto.cert\n",
    "!echo QUIT | openssl s_client -showcerts -connect localhost:8443 | awk '/-----BEGIN CERTIFICATE-----/ {p=1}; p; /-----END CERTIFICATE-----/ {p=0}' > /tmp/presto.crt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d7823-aa5b-40f2-9e61-0a4127f59f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = %system echo QUIT | openssl s_client -showcerts -connect watsonxdata:8443 | \\\n",
    "        awk '/-----BEGIN CERTIFICATE-----/ {p=1}; p; /-----END CERTIFICATE-----/ {p=0}' > /tmp/presto.crt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedf1d76-7623-47f7-966b-8afb5ff92007",
   "metadata": {},
   "source": [
    "### Local Connection Parameters\n",
    "\n",
    "Please change the values for apiuser and apikey to the values provided in the lab guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313a49a-fa0c-4d49-91fe-48a6c77f0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "host            = 'watsonxdata'\n",
    "port            = 19530\n",
    "apiuser         = 'xxxxxxxxxx'\n",
    "apikey          = 'xxxxxxxx'\n",
    "server_pem_path = '/tmp/presto.crt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7519ee-3ff9-4952-a1b7-8280857547be",
   "metadata": {},
   "source": [
    "## Milvus Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814994c5-c60a-4be9-b564-81f714abb609",
   "metadata": {},
   "source": [
    "### We use MilvusClient instead of the connection function of the ORM API this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c05a25-19c4-4c8d-9ca5-58df16e04721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "print (dir(MilvusClient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610dfab5-c4fe-4e4f-971e-1d4a777bd2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "client = MilvusClient(\n",
    "    uri=f\"http://{host}:{port}\",\n",
    "    token=f\"{apiuser}:{apikey}\",\n",
    "    server_pem_path=server_pem_path,\n",
    "    secure=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88891718-6a17-48a4-818a-4a0ec22033fd",
   "metadata": {},
   "source": [
    "### Check Connection Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c68194-8f9f-4334-8361-1864f6601286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections\n",
    "\n",
    "print(f\"\\nList connections:\")\n",
    "print(connections.list_connections())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f277f-e5bf-475a-b422-eefe1fe604ed",
   "metadata": {},
   "source": [
    "## Create a Collection in Milvus\n",
    "This code will drop the wiki_articles collection if it exists, and then recreate it. This script should return the following text.\n",
    "```\n",
    "Status(code=0, message=)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0dfcc0-03db-4a40-8be8-5e9c775d0aa3",
   "metadata": {},
   "source": [
    "#### Make various unitilty commands available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6aa9c-355e-4f9b-90a8-98f0de2f1f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import utility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3feb49-1e5e-411f-81f9-d4090beaadf4",
   "metadata": {},
   "source": [
    "#### Clean up previous collection if one already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3257de0-eda9-4c6e-9354-abe6e9633f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.drop_collection(\"wiki_articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e3c29-c159-427b-a4cf-ceec51df1c00",
   "metadata": {},
   "source": [
    "### Create a sample collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e17ace7-6e96-4f3b-9364-fe35f2dd3a47",
   "metadata": {},
   "source": [
    "#### Define the schema for our collection \n",
    "\n",
    "Since we want to perform a hybrid query which means that the query involves several vectors, we define two vector fields besides the scalar fields in our collection. The two vectors which we define are of the same type, but in general they can be very different. Some vectors can be dense vectors, other vectors can be sparse vetors. They can have different dimensions and can represent differengt kinds of data like text, audio, video, or images.\n",
    "\n",
    "In our case the field \"vector\" is a representation of a chunk of a Wikipedia article like in the previous labs. We assume that we have textual representation of emotions (review comments) on each chunk of data. We present these emotions with a vector field with name \"vectoremotion\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8c977-5ec9-4974-9aeb-289c3c4871ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import DataType\n",
    "\n",
    "schema = MilvusClient.create_schema(\n",
    "    auto_id=False,\n",
    "    enable_dynamic_field=False,\n",
    ")\n",
    "\n",
    "schema.add_field(field_name=\"id\", datatype=DataType.INT64, is_primary=True) # Primary key\n",
    "schema.add_field(field_name=\"article_text\", datatype=DataType.VARCHAR, max_length=2500)\n",
    "schema.add_field(field_name=\"article_title\", datatype=DataType.VARCHAR, max_length=200)\n",
    "schema.add_field(field_name=\"article_subtopic\", datatype=DataType.VARCHAR, max_length=10)\n",
    "schema.add_field(field_name=\"emotion\", datatype=DataType.VARCHAR, max_length=30)\n",
    "schema.add_field(field_name=\"vector\", datatype=DataType.FLOAT_VECTOR, dim=384)\n",
    "schema.add_field(field_name=\"vectoremotion\", datatype=DataType.FLOAT_VECTOR, dim=384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116bc5ac-fba5-481c-b9df-f45d594aa345",
   "metadata": {},
   "source": [
    "#### Check which collections already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6270c-a011-41ba-934e-986ce3eac3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.list_collections()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aeb3fd-5448-4f14-aa0a-f2dc54ba7dc0",
   "metadata": {},
   "source": [
    "#### Create indexes for the two vector fields of our collection\n",
    "\n",
    "Since we want to query to vector fields at the same time, we have to index both of these vector fields. In general a hybrid query query can involve many vector fields (of different dimensions with different kinds of indexes. In our case we choose for simplicity reasons the same kind on vector index (IVF_FLAT) for both columns.\n",
    "\n",
    "- metric_type specifies the distance metric used in the vector space. L2 is the Euclidian distance.\n",
    "- index_type specifies the type of vector index to use. IVF means inverted file index which means clusting the the vector space and representing each cluster by its centroid. FLAT means that vectors are stored directly without any compression or quantization meaning that precise distance calculations are possible\n",
    "- params specifies several parameters relevant for our index. For instance nlist defines the number clusters to use for the inverted file index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae23e5d-978b-4e73-9278-caaaebde9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "index_params = client.prepare_index_params()\n",
    "\n",
    "index_params.add_index(\n",
    "    field_name=\"vector\",\n",
    "    index_name=\"vector_index\",\n",
    "    index_type=\"IVF_FLAT\",\n",
    "    metric_type=\"L2\",\n",
    "    params={\"nlist\":2048}\n",
    ")\n",
    "\n",
    "index_params.add_index(\n",
    "    field_name=\"vectoremotion\",\n",
    "    index_name=\"vectoremotion_index\",\n",
    "    index_type=\"IVF_FLAT\",\n",
    "    metric_type=\"L2\",\n",
    "    params={\"nlist\":2048}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d57c1-cf31-415c-bdf5-45d71e416c9f",
   "metadata": {},
   "source": [
    "#### After having prepared the schema and the index definitions for our collection we can create the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e53bde-bbc0-484a-9f6a-3a239b9ecd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_collection(collection_name=\"wiki_articles\", schema=schema, index_params=index_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21e7b8-6212-465b-9ce2-dd1d50a8ebee",
   "metadata": {},
   "source": [
    "#### Double Check that the Schema Exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ae789-f4d8-4a14-a119-15b7d9cccc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.list_collections()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29c0c3c-3161-460c-8f74-3b7d55ce5044",
   "metadata": {},
   "source": [
    "## Get data from Wikipedia for loading into our collection\n",
    "\n",
    "This is done in the same way as for labs 1 to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddeba1-e82d-45c4-be19-85448d73ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# search\n",
    "search_results = wikipedia.search(\"Climate\")\n",
    "\n",
    "articles = []\n",
    "for i in range (0,len(search_results)):\n",
    "    try:\n",
    "        summary = wikipedia.summary(search_results[i],auto_suggest=False)\n",
    "    except Exception as err:\n",
    "        print(f\"Skipped article '{search_results[i]}' skipped because of ambiguity.\")\n",
    "        continue\n",
    "    try:\n",
    "        page = wikipedia.page(search_results[i],auto_suggest=False).content\n",
    "    except Exception as err:\n",
    "        print(f\"Skipped article '{search_results[i]}' skipped because of ambiguity.\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    articles.append({\n",
    "        \"title\"   : search_results[i],\n",
    "        \"summary\" : summary,\n",
    "        \"page\"    : page\n",
    "    })\n",
    "\n",
    "#print(display_articles)\n",
    "\n",
    "df = pd.DataFrame.from_dict(articles)\n",
    "df.style.set_properties(**{'text-align': 'left'})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b35b0-55b7-4a74-b5f1-8018e89b81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20262775-5398-46ec-93d4-f58aca121679",
   "metadata": {},
   "source": [
    "## Emotions for chunks\n",
    "\n",
    "In this lab we will assume that short emotional comments will exist for each chunk of a wikepedia article. We will use that to store a second vector with these emotions so that we can later perform a search involving two different vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf9adbb-357e-4334-8cb4-518462393e7b",
   "metadata": {},
   "source": [
    "### Prepare some emotion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc072b1a-ef64-47ae-9c5c-22dce649250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionlist=[\"Very good!\", \"Highly recommended!\", \"Great quality!\", \"Excellent!\", \"Will not read again!\", \n",
    "             \"Meets my needs\", \"Good product\", \"As expected\",\"Average quality\", \"Does the job\", \"Just alright\", \n",
    "             \"Nothing special\",\"Disappointed!\", \"Expected more\", \"OK\", \"Mediocre\",\"Terrible!\", \n",
    "             \"Not recommended!\", \"Never again!\", \"Worst ever\"]\n",
    "el_len=len(emotionlist)\n",
    "print(el_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc2c1f3-b919-45dc-9a98-ccebe7480b6b",
   "metadata": {},
   "source": [
    "## Split Articles into chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8d8fd-844e-4315-b82d-c6bb3037340b",
   "metadata": {},
   "source": [
    "### Define function for splitting article into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64fabfe-715c-4e81-a245-9865e13f69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk data\n",
    "def split_into_chunks(text, chunk_size):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22864a5d-42e2-487c-917d-cceef9cf0e40",
   "metadata": {},
   "source": [
    "### Create list of chunks for all articles and create analog list for additional metadata corresponding to the chunk (title, subtopic)\n",
    "\n",
    "We also create emotions for the chunks by randomly assigning one of the emotions to each chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9df370-2183-4b89-97a3-01bd675feb4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import seed, randrange\n",
    "\n",
    "seed(0)\n",
    "\n",
    "chunk_size=255\n",
    "passages=[]\n",
    "passages_titles=[]\n",
    "passages_subtopic=[]\n",
    "passages_emotion=[]\n",
    "\n",
    "for a in articles:\n",
    "    print('title',a['title'])\n",
    "    if a['title'] == \"Climate\":\n",
    "        subtopic=\"false\"\n",
    "    else:\n",
    "        subtopic=\"true\"\n",
    "    \n",
    "    p = a['page']\n",
    "    cl = split_into_chunks(p,chunk_size)\n",
    "    \n",
    "    print(\"number of chunks=\",len(cl))\n",
    "    for c in cl:\n",
    "        passages.append(c)\n",
    "        passages_titles.append(a['title'])\n",
    "        passages_subtopic.append(subtopic)\n",
    "        r=randrange(0,20)\n",
    "        passages_emotion.append(emotionlist[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd36679-b940-488c-9369-20d543a58626",
   "metadata": {},
   "source": [
    "### Create the embeddings for the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10145813-aa87-4117-9492-d98200b06585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') # 384 dim\n",
    "\n",
    "passages_embeddings = model.encode(passages)\n",
    "passages_emotion_embeddings = model.encode(passages_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd52d3-791b-473c-972d-742cf129d7de",
   "metadata": {},
   "source": [
    "### Insert all data into the collection created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127cad62-a4e2-4b51-b946-6d63c8496e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# create a list of dictionary with each dirctionary corresponding to a row in the collection which we want to insert into.\n",
    "for i in range(0,len(passages)):\n",
    "   data.append({\n",
    "       \"id\": i, \n",
    "       \"article_text\": passages[i], \n",
    "       \"article_title\": passages_titles[i], \n",
    "       \"article_subtopic\": passages_subtopic[i],\n",
    "       \"emotion\": passages_emotion[i],\n",
    "       \"vector\": passages_embeddings[i],\n",
    "       \"vectoremotion\": passages_emotion_embeddings[i]\n",
    "   })\n",
    "\n",
    "# insert the data from the above list into our collection\n",
    "client.insert(collection_name=\"wiki_articles\",data=data)\n",
    "\n",
    "# make sure that the data is written to external storage \n",
    "client.flush(\n",
    "    collection_name=\"wiki_articles\"\n",
    ")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54aee5f-ce89-488a-bd2d-976f89242301",
   "metadata": {},
   "source": [
    "## Hybrid Multi-Vector Queries with Milvus \n",
    "\n",
    "The following code shows how you can perform a hybrid multi-vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5754b93-b7b4-4c11-a569-b4d0e570ecf7",
   "metadata": {},
   "source": [
    "### Load the Collection into memory and check that the Collection has been Loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d82152-41f7-45e4-8350-076ea5426f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the collection\n",
    "client.load_collection(\n",
    "    collection_name=\"wiki_articles\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10bf982-327e-4836-9aa1-05373160b17e",
   "metadata": {},
   "source": [
    "### Check whether the collection is actually loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ac0d6-a9f2-4ace-85a4-272244328e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.get_load_state(\n",
    "    collection_name=\"wiki_articles\"\n",
    ")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468baef5-fe44-4315-bf95-a1ceb54e7dcb",
   "metadata": {},
   "source": [
    "### Check how many rows got loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f06cda-f433-41f7-9680-d55730ebe5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_collection_stats(collection_name=\"wiki_articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92d642-c899-4187-9df8-1a5d780c8cb3",
   "metadata": {},
   "source": [
    "## Query Milvus & Prompt LLM\n",
    "After gathering the data from Wikipedia and then vectorizing it and inserting into Milvus, we are now ready to perform queries against the vector database. We will use the `sentence-transformers/all-MiniLM-L6-v2` model to generate the query vector and then use Milvus to find the most similar vectors in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41419cc9-7e1d-4996-b9d6-29baca4cf21a",
   "metadata": {},
   "source": [
    "### Create a Query Function\n",
    "The following function will be used to query the collection with a hybrid query. A hybrid query includes more than one vector column (in our example it will be two vector columns). This can for instance be used to combine the search on image data with the search on text data. In our case we will combine search on the article with emotions saved for the different parts of the article. Of course the results of the queries of the different vectors will have to be merged. This is done by reranking the results of the individual vector searchs. There are several rerankers available which can place different weights on the results of the individual queries.\n",
    "\n",
    "We use the Reciprocal Rank Fusion (RRF) Ranker. This is a reranking strategy for Milvus hybrid search that balances results from multiple vector searches based on their ranking positions rather than their raw similarity scores. \n",
    "RRF Ranker combines search results based on how highly each item ranks in each individual query, creating a fair and balanced final ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84794c22-5530-4ee0-b758-3f90fb4415b4",
   "metadata": {},
   "source": [
    "#### Get the ranker first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb46ef2-20e5-4aa1-8c30-1b797245c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import RRFRanker\n",
    "# The parameter of RRFRanker is a smoothing parameter. It must be in  the range 0 to 16384. It is recommended having a value between 10 and 100.\n",
    "ranker = RRFRanker(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5905470-9db1-4571-9db9-7c574775fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from pymilvus import AnnSearchRequest\n",
    "\n",
    "def hybrid_query_milvus(query, query_emotion, num_results=5):\n",
    "    #print(\"query=<\",query,\"> query_emotion=<\",query_emotion,\"> num_results=<\",num_results,\">\")\n",
    "    # Vectorize query and query_emotion\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') # 384 dim\n",
    "    query_embeddings = model.encode([query])\n",
    "    query_emotion_embeddings = model.encode([query])\n",
    "    #print(\"query_embeddings\",query_embeddings)\n",
    "    #print(\"query_emotion_embeddings\",query_emotion_embeddings)\n",
    "\n",
    "    # Prepare the searches for the two vectors in our collection\n",
    "    # data is the search vector (created via embedding of the original query text) \n",
    "    # anns_field specifies the name of the vector field we are searching in\n",
    "    # params can have indiviual parameters relevant for the particular index used\n",
    "    # limit determines how many results should be returned\n",
    "    \n",
    "    search_param_1 = {\n",
    "        \"data\": query_embeddings,\n",
    "        \"anns_field\": \"vector\",\n",
    "        \"param\": {\"nprobe\": 10},\n",
    "        \"limit\": num_results\n",
    "    }\n",
    "    request_1 = AnnSearchRequest(**search_param_1)\n",
    "    \n",
    "    search_param_2 = {\n",
    "        \"data\": query_emotion_embeddings,\n",
    "        \"anns_field\": \"vectoremotion\",\n",
    "        \"param\": {\"nprobe\": 10},\n",
    "        \"limit\": num_results\n",
    "    }\n",
    "    request_2 = AnnSearchRequest(**search_param_2)\n",
    "\n",
    "    reqs = [request_1, request_2]\n",
    "    # print(reqs)    \n",
    "\n",
    "    results = client.hybrid_search(\n",
    "        collection_name=\"wiki_articles\",\n",
    "        reqs=reqs,\n",
    "        ranker=ranker,\n",
    "        limit=num_results,\n",
    "        output_fields=['article_text','emotion']\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7a456-fb25-4baa-b178-8f8d7c8a8355",
   "metadata": {},
   "source": [
    "### Suggestions for querys\n",
    "\n",
    "For the hybrid query we need a query on the Wikipedia articles (question_text) and a query on the emotions (emotion_text) which will be combined. Uncomment one of the examples in each of the two catagories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f53ed21-e3d6-41a6-a036-a92e9cb8ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_text = \"What can my company do to help fight climate change?\"\n",
    "#question_text = \"How do businesses negatively effect climate change?\"\n",
    "#question_text = \"What can a businesses do to have a positive effect on climate change?\"\n",
    "#question_text = \"How can a business reduce their carbon footprint?\"\n",
    "\n",
    "emotion_text = \"very good\"\n",
    "#emotion_text = \"this is ok\"\n",
    "#emotion_text = \"bad\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd40587e-a81d-4628-99df-71b959bef6ee",
   "metadata": {},
   "source": [
    "### Search a Question in Milvus\n",
    "\n",
    "We want to use the above question_text and emotion_text to perform a approximate nearest neighbor search in Milvus.  The top 3 related chunks are retrieved below and can be used for a large language prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dfe039-4763-4278-b843-d408c10a4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_results = 3\n",
    "\n",
    "results = hybrid_query_milvus(question_text, emotion_text, num_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a12b5-6b44-4e68-9143-184677d4e928",
   "metadata": {},
   "source": [
    "## Display result\n",
    "\n",
    "The documents that best match the question are now displayed in the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64ceaf3-18d9-48cc-be40-011e894721b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hits in results:\n",
    "    print(\"TopK results:\")\n",
    "    for hit in hits:\n",
    "        print(hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7783e1-9602-4fc1-b669-a44e18c0fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "display_articles = []\n",
    "relevant_chunks  = []\n",
    "for i in range(num_results):\n",
    "    display_articles.append({\n",
    "        \"ID\"      : results[0].ids[i],\n",
    "        \"Distance\": results[0].distances[i],\n",
    "        \"Emotion\": results[0][i].entity.get('emotion'),\n",
    "        \"Article\" : re.sub(r\"^.*?\\. (.*\\.).*$\",r\"\\1\",results[0][i].entity.get('article_text'))        \n",
    "    })\n",
    "    relevant_chunks.append(re.sub(r\"^.*?\\. (.*\\.).*$\",r\"\\1\",results[0][i].entity.get('article_text')))\n",
    "\n",
    "df = pd.DataFrame.from_dict(display_articles).sort_values(\"Distance\",ascending=False)\n",
    "df.style.set_properties(**{'text-align': 'left'}).set_caption(question_text + \" / \" + emotion_text).set_table_styles([{\n",
    "    'selector': 'caption',\n",
    "    'props': [\n",
    "        ('color', 'blue'),\n",
    "        ('font-size', '20px')\n",
    "    ]\n",
    "}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b413cf1b-f8f3-47b8-91ff-906a5a42c3ae",
   "metadata": {},
   "source": [
    "#### Credits: IBM 2025, Wilfried Hoge [hoge@de.ibm.com] and Andreas Weininger [andreas.weininger@de.ibm.com] based on a notebook by George Baklarz [baklarz@ca.ibm.com]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
